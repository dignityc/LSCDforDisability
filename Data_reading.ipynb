{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = ['ADHD', 'Blind', 'Disability']\n",
    "df_list = []\n",
    "for d in dataset_name:\n",
    "    df_list.append(pd.read_csv(f'datasets/2nd_filtering/{d}_relevance.csv', index_col=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====dataset:ADHD======\n",
      "Posts:56197\n",
      "Tokens:10812473\n",
      "Types:5613877\n",
      "TTR:519.2\n",
      "Avg. of tokens:192.4\n",
      "Avg. of types:99.9\n",
      "Sentiment ratio:1.06\n",
      "Relevance ratio:13.64\n",
      "=====dataset:Blind======\n",
      "Posts:1008\n",
      "Tokens:214930\n",
      "Types:108452\n",
      "TTR:504.59\n",
      "Avg. of tokens:213.22\n",
      "Avg. of types:107.59\n",
      "Sentiment ratio:0.74\n",
      "Relevance ratio:10.33\n",
      "=====dataset:Disability======\n",
      "Posts:2434\n",
      "Tokens:527366\n",
      "Types:264690\n",
      "TTR:501.91\n",
      "Avg. of tokens:216.67\n",
      "Avg. of types:108.75\n",
      "Sentiment ratio:1.51\n",
      "Relevance ratio:14.6\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(dataset_name):\n",
    "    df = df_list[i]\n",
    "    df['token_count'] = df['anonymized_body_lemmatized'].apply(lambda x: len(ast.literal_eval(x)))\n",
    "    df['token_type_count'] = df['anonymized_body_lemmatized'].apply(lambda x: len(set(ast.literal_eval(x))))\n",
    "    print(f'=====dataset:{d}======')\n",
    "    print(f\"Posts:{df.shape[0]}\")\n",
    "    print(f\"Tokens:{df['token_count'].sum()}\")\n",
    "    print(f\"Types:{df['token_type_count'].sum()}\")\n",
    "    print(f\"TTR:{(df['token_type_count'].sum()/df['token_count'].sum()*1000).round(2)}\")\n",
    "    print(f\"Avg. of tokens:{df['token_count'].mean().round(2)}\")\n",
    "    print(f\"Avg. of types:{df['token_type_count'].mean().round(2)}\")\n",
    "    sentiment = df['post_sentiment_label'].apply(lambda x: 1 if x == 'negative' else 0)\n",
    "    print(f\"Sentiment ratio:{(sentiment.value_counts()[1]/sentiment.value_counts()[0]).round(2)}\")\n",
    "    print(f\"Relevance ratio:{(df['Relevance'].value_counts()[1]/df['Relevance'].value_counts()[0]).round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_csv('all_predictions.csv', index_col =0)\n",
    "scores = pd.read_csv('all_scores.csv', index_col =0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = []\n",
    "for m in scores['model'].unique():\n",
    "    score = scores[(scores['dataset'] == 'Disability') & (scores['model'] == m)]\n",
    "    summary.append({'model': m, 'acc': score['acc'].mean(), 'prec': score['prec'].mean(), 'rec': score['rec'].mean(), 'f1-score': score['f1-score'].mean()})\n",
    "pd.DataFrame(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>acc</th>\n",
       "      <th>prec</th>\n",
       "      <th>rec</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llama2_7b_pred</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.547472</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.707261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama2_13b_pred</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TimeLMs_label</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hatexplain_label</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama2_7b_FL_pred</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.652871</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.786254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama2_13b_FL_pred</td>\n",
       "      <td>0.665</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.494505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model    acc      prec   rec  f1-score\n",
       "0      llama2_7b_pred  0.585  0.547472  1.00  0.707261\n",
       "1     llama2_13b_pred  0.850  0.888889  0.80  0.842105\n",
       "2       TimeLMs_label  0.500  0.500000  1.00  0.666667\n",
       "3    hatexplain_label  0.500  0.500000  1.00  0.666667\n",
       "4   llama2_7b_FL_pred  0.730  0.652871  0.99  0.786254\n",
       "5  llama2_13b_FL_pred  0.665  1.000000  0.33  0.494505"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
